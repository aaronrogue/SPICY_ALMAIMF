{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5253038-a490-485a-8230-b4a9fbba9160",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ALMA-IMF+SPICY: SED Table Prep\n",
    "\n",
    "Workspace for acquiring and assembling SED data points and upper limits into tables and saving them to fits files (one per field). These files will be loaded into the SED Fitting workspace. Search for \"!filepath!\" to locate files/filepath references if they need to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984bb194-6b20-4270-b385-edd35431fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# utility\n",
    "from tqdm import tqdm\n",
    "\n",
    "# astropy\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.table import vstack\n",
    "from astropy import table\n",
    "from astropy import coordinates\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "from astropy import wcs\n",
    "from astropy.wcs import WCS\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.ukidss import Ukidss\n",
    "from astroquery.svo_fps import SvoFps\n",
    "\n",
    "from sedfitter.filter import Filter\n",
    "\n",
    "# photutils\n",
    "import sys\n",
    "import photutils\n",
    "sys.path.append('/orange/adamginsburg/ALMA_IMF/reduction/analysis/') # !filepath!\n",
    "from spectralindex import prefixes\n",
    "from spectral_cube import SpectralCube\n",
    "\n",
    "# convenience-sorting of fields based on which NIR observations they have\n",
    "ukidss_fields = ['G10','G12','W43MM1','W43MM2','W43MM3','W51-E','W51IRS2']\n",
    "virac_fields = ['G008','G327','G328','G333','G337','G338','G351','G353']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7620ab6-971b-4b47-8d51-22fcaf0da764",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a7229c-7d66-46c8-a637-c881beb4a171",
   "metadata": {},
   "source": [
    "Getting sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9685d8-ad9c-422e-a68f-b9a8edcfc262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spicy_tbl():\n",
    "    # retrieve the SPICY catalog\n",
    "    tbl = Table.read('/blue/adamginsburg/adamginsburg/ALMA_IMF/SPICY_ALMAIMF/table1.fits') # !filepath!\n",
    "        #alternatively: tbl = Table.read('https://sites.astro.caltech.edu/~mkuhn/SPICY/table1.fits')\n",
    "    coords = SkyCoord(tbl['l'], tbl['b'], frame='galactic', unit=(u.deg, u.deg))\n",
    "    return tbl,coords\n",
    "\n",
    "def find_ALMAIMF_matches(tbl, coords):\n",
    "    # determine number of SPICY sources in each ALMA FOV\n",
    "    os.chdir('/orange/adamginsburg/web/secure/ALMA-IMF/May2021Release/') # !filepath!\n",
    "\n",
    "    prefixes['W43MM1'] = dict(\n",
    "        finaliter_prefix_b3=\"W43-MM1/B3/cleanest/W43-MM1_B3_uid___A001_X1296_X1af_continuum_merged_12M_robust0_selfcal4_finaliter\",\n",
    "        finaliter_prefix_b6=\"W43-MM2/B6/cleanest/W43-MM2_B6_uid___A001_X1296_X113_continuum_merged_12M_robust0_selfcal5_finaliter\",) # !filepath!\n",
    "\n",
    "    all_matches = np.zeros(len(tbl), dtype='bool')\n",
    "    fieldids = np.empty(len(tbl), dtype='S8')\n",
    "\n",
    "    for fieldid, pfxs in prefixes.items():\n",
    "        cube = SpectralCube.read(pfxs['finaliter_prefix_b3']+\".image.tt0.fits\", format='fits', use_dask=False).minimal_subcube() # !filepath!\n",
    "        ww = cube.wcs.celestial\n",
    "        ww._naxis = cube.shape[1:]\n",
    "        matches = ww.footprint_contains(coords)\n",
    "        all_matches |= matches\n",
    "        fieldids[matches] = fieldid\n",
    "\n",
    "    tbl['in_ALMAIMF'] = all_matches\n",
    "    tbl['ALMAIMF_FIELDID'] = fieldids\n",
    "    return tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167aa520-7416-432a-ab3b-3b881843f530",
   "metadata": {},
   "source": [
    "Utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2134af-64b2-483d-8824-6c7a96f4f444",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_flx(crd, data, ww):\n",
    "    crd = crd.transform_to(ww.wcs.radesys.lower())\n",
    "    xpix, ypix = ww.world_to_pixel(crd)\n",
    "    xpix = int(np.round(xpix))\n",
    "    ypix = int(np.round(ypix))\n",
    "    return data[ypix, xpix]\n",
    "\n",
    "def get_filters(hemisphere='south'):\n",
    "    # these are the official filternames on SVO_FPS\n",
    "    if hemisphere == 'north':\n",
    "        filternames = ['UKIRT/UKIDSS.J', 'UKIRT/UKIDSS.H', 'UKIRT/UKIDSS.K',\n",
    "                   'Spitzer/IRAC.I1', 'Spitzer/IRAC.I2', 'Spitzer/IRAC.I3', 'Spitzer/IRAC.I4', 'Spitzer/MIPS.24mu',\n",
    "                   'Herschel/Pacs.blue', 'Herschel/Pacs.red', 'Herschel/SPIRE.PSW', 'Herschel/SPIRE.PMW', 'Herschel/SPIRE.PLW'\n",
    "                  ]\n",
    "        # keep only the non \"_ext\" SPIRE filters (but we should look up which is more appropriate)\n",
    "        spire_filters = SvoFps.get_filter_list(facility='Herschel', instrument='Spire')\n",
    "        spire_filters = spire_filters[['_ext' not in fid for fid in spire_filters['filterID']]]\n",
    "        \n",
    "        filter_meta = table.vstack([SvoFps.get_filter_list(facility='UKIRT', instrument='WFCAM'),\n",
    "                                SvoFps.get_filter_list(facility='Spitzer', instrument='IRAC'),\n",
    "                                SvoFps.get_filter_list(facility='Spitzer', instrument='MIPS')[0],\n",
    "                                SvoFps.get_filter_list(facility='Herschel', instrument='Pacs'),\n",
    "                                spire_filters,\n",
    "                               ])\n",
    "        \n",
    "    elif hemisphere == 'south':\n",
    "        filternames = ['Paranal/VISTA.Y', 'Paranal/VISTA.Z', 'Paranal/VISTA.J', 'Paranal/VISTA.H', 'Paranal/VISTA.Ks',\n",
    "                   'Spitzer/IRAC.I1', 'Spitzer/IRAC.I2', 'Spitzer/IRAC.I3', 'Spitzer/IRAC.I4', 'Spitzer/MIPS.24mu',\n",
    "                   'Herschel/Pacs.blue', 'Herschel/Pacs.red', 'Herschel/SPIRE.PSW', 'Herschel/SPIRE.PMW', 'Herschel/SPIRE.PLW'\n",
    "                  ]\n",
    "        # keep only the non \"_ext\" SPIRE filters (but we should look up which is more appropriate)\n",
    "        spire_filters = SvoFps.get_filter_list(facility='Herschel', instrument='Spire')\n",
    "        spire_filters = spire_filters[['_ext' not in fid for fid in spire_filters['filterID']]]\n",
    "        \n",
    "        filter_meta = table.vstack([SvoFps.get_filter_list(facility='Paranal', instrument='VIRCAM'),\n",
    "                                SvoFps.get_filter_list(facility='Spitzer', instrument='IRAC'),\n",
    "                                SvoFps.get_filter_list(facility='Spitzer', instrument='MIPS')[0],\n",
    "                                SvoFps.get_filter_list(facility='Herschel', instrument='Pacs'),\n",
    "                                spire_filters,\n",
    "                               ])\n",
    "\n",
    "    zpts = {filtername: filter_meta[filter_meta['filterID']==filtername]['ZeroPoint'] for filtername in filternames}\n",
    "\n",
    "    filtercurves = {filtername: SvoFps.get_transmission_data(filtername) for filtername in filternames}\n",
    "    wavelengths = [np.average(filtercurves[filtername]['Wavelength'],\n",
    "                              weights=filtercurves[filtername]['Transmission'])\n",
    "                  for filtername in filternames]\n",
    "    wavelength_dict = {filtername: np.average(filtercurves[filtername]['Wavelength'],\n",
    "                                              weights=filtercurves[filtername]['Transmission'])*u.AA\n",
    "                       for filtername in filternames}\n",
    "\n",
    "    filterfreqs = {filtername: u.Quantity(filtercurves[filtername]['Wavelength'], u.AA).to(u.Hz, u.spectral()) for filtername in filternames}\n",
    "    filtertrans = {filtername: np.array(filtercurves[filtername]['Transmission'])[np.argsort(filterfreqs[filtername])]\n",
    "                  for filtername in filternames}\n",
    "    filterfreqs = {filtername: np.sort(filterfreqs[filtername]) for filtername in filternames}\n",
    "\n",
    "    sed_filters = [Filter(name=filtername,\n",
    "                          central_wavelength=wl*u.AA,\n",
    "                          nu=filterfreqs[filtername],\n",
    "                          response=filtertrans[filtername])\n",
    "                   for filtername, wl in zip(filternames, wavelengths)]\n",
    "\n",
    "\n",
    "    # Add in the custom ALMA-IMF filters\n",
    "    almaimf_bandends_1mm = [[216.10085679, 216.36181569],\n",
    "                            [217.05104378, 217.31175857],\n",
    "                            [219.90488464, 220.04866835],\n",
    "                            [218.13102322, 218.39222624],\n",
    "                            [219.51976276, 219.66379059],\n",
    "                            [230.31532951, 230.81137113],\n",
    "                            [231.06503709, 231.56181105],\n",
    "                            [231.52507012, 233.42623749]]*u.GHz\n",
    "    nu_1mm = np.linspace(almaimf_bandends_1mm.min(), almaimf_bandends_1mm.max(), 5000)\n",
    "    response_1mm = np.zeros(nu_1mm.size, dtype='bool')\n",
    "    for start, stop in almaimf_bandends_1mm:\n",
    "        response_1mm |= (nu_1mm > start) & (nu_1mm < stop)\n",
    "    sed_filters.append(Filter(name='ALMA-IMF_1mm',\n",
    "                              central_wavelength=(228.15802*u.GHz).to(u.mm, u.spectral()),\n",
    "                              nu=nu_1mm,\n",
    "                              response=response_1mm.astype(float),\n",
    "                             ))\n",
    "\n",
    "    for filterfunc in sed_filters:\n",
    "        filterfunc.normalize()\n",
    "\n",
    "\n",
    "    almaimf_bandends_3mm = [[ 93.13410936,  93.25141259],\n",
    "                            [ 91.75059068,  92.68755174],\n",
    "                            [102.15273354, 103.0896946 ],\n",
    "                            [104.55323851, 105.49019957]]*u.GHz\n",
    "    nu_3mm = np.linspace(almaimf_bandends_3mm.min(), almaimf_bandends_3mm.max(), 5000)\n",
    "    response_3mm = np.zeros(nu_3mm.size, dtype='bool')\n",
    "    for start, stop in almaimf_bandends_3mm:\n",
    "        response_3mm |= (nu_3mm > start) & (nu_3mm < stop)\n",
    "    sed_filters.append(Filter(name='ALMA-IMF_3mm',\n",
    "                              central_wavelength=(99.68314596*u.GHz).to(u.mm, u.spectral()),\n",
    "                              nu=nu_3mm,\n",
    "                              response=response_3mm.astype(float),\n",
    "                             ))\n",
    "\n",
    "    wavelength_dict['ALMA-IMF_1mm'] = (228.15802*u.GHz).to(u.um, u.spectral())\n",
    "    wavelength_dict['ALMA-IMF_3mm'] = (99.68314596*u.GHz).to(u.um, u.spectral())\n",
    "\n",
    "    return sed_filters, wavelength_dict, filternames, zpts\n",
    "\n",
    "def mag_to_flux(tbl, magcols, emagcols, zpts, filternames):\n",
    "    # convert magnitudes to fluxes\n",
    "    # (it's a pain to try to deal with a mix of magnitudes & fluxes)\n",
    "    for colname, errcolname, zpn in zip(magcols, emagcols, filternames):\n",
    "        zp = u.Quantity(zpts[zpn], u.Jy)\n",
    "        # iterate through each colname\n",
    "        if colname and errcolname in tbl.keys():\n",
    "            #grab numerical value for the data; masked should be nan\n",
    "            data = tbl[colname]\n",
    "            error = tbl[errcolname]\n",
    "            print(colname)\n",
    "            if hasattr(tbl[colname], 'mask'):\n",
    "                tbl[zpn+\"_flux\"] = flx = np.ma.masked_where(tbl[colname].mask, (zp * 10**(data.data/-2.5)).to(u.mJy))\n",
    "            else:\n",
    "                tbl[zpn+\"_flux\"] = flx = (zp * 10**(data.data/-2.5)).to(u.mJy)\n",
    "                \n",
    "            if hasattr(tbl[errcolname], 'mask') and hasattr(tbl[colname], 'mask'):\n",
    "                tbl[zpn+\"_eflux\"] = err = np.ma.masked_where(tbl[errcolname].mask, np.where(tbl[colname].mask, (zp * 10**(error.data/-2.5)).to(u.mJy), error.quantity / (1.09*u.mag) * flx.data))\n",
    "            elif not hasattr(tbl[errcolname], 'mask') and hasattr(tbl[colname], 'mask'):\n",
    "                tbl[zpn+\"_eflux\"] = err = np.where(tbl[colname].mask, (zp * 10**(error.data/-2.5)).to(u.mJy), error.quantity / (1.09*u.mag) * flx.data)\n",
    "            else:\n",
    "                tbl[zpn+\"_eflux\"] = err = error.quantity / (1.09*u.mag) * flx.data\n",
    "            tbl[zpn+\"_flux\"].unit = 'mJy'\n",
    "            tbl[zpn+\"_eflux\"].unit = 'mJy'\n",
    "            #err = tbl[errcolname] / (1.09*u.mag) * flx\n",
    "            #tbl[zpn+\"_eflux\"] = err\n",
    "        else: print(f'{colname} not found.')\n",
    "        \n",
    "    return tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cfad2b-13f7-439f-9738-6c38407b7bbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "Adding more data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404bbb5b-f20e-483e-88e8-f389f359ef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# SPICY\n",
    "# ----------------\n",
    "\n",
    "def add_spicylimits(tbl, spicyupperlims = {\"3_6\": 14.9,\n",
    "                  \"4_5\": 13.7,\n",
    "                  \"5_8\": 12.9,\n",
    "                  \"8_0\": 12.2,}):\n",
    "    for key in spicyupperlims.keys():\n",
    "        if f'mag{key}' and f'e_mag{key}' in tbl.keys():\n",
    "            tbl[f'e_mag{key}'] = table.MaskedColumn(tbl[f'e_mag{key}'])\n",
    "            tbl[f'e_mag{key}'].fill_value = spicyupperlims[key]\n",
    "            try:\n",
    "                tbl[f'e_mag{key}'] = tbl[f'e_mag{key}'].filled()\n",
    "            except AttributeError:\n",
    "                print(f\"Column {key} has no masked values\")\n",
    "        else: print(f'{key} band not found.')\n",
    "    return tbl\n",
    "\n",
    "# ----------------\n",
    "# ALMA\n",
    "# ----------------\n",
    "\n",
    "def add_alma_photometry(tbl, aperture_radius=3*u.arcsec,\n",
    "                        annulus_inner=3*u.arcsec, annulus_outer=5*u.arcsec,\n",
    "                        basepath='/orange/adamginsburg/ALMA_IMF/2017.1.01355.L/RestructuredImagingResults',\n",
    "                        band='b3', wlname='3mm'): # !filepath!\n",
    "\n",
    "    tbl[f'ALMA-IMF_{wlname}_flux'] = np.zeros(len(tbl), dtype='float')\n",
    "    tbl[f'ALMA-IMF_{wlname}_eflux'] = np.zeros(len(tbl), dtype='float')\n",
    "\n",
    "    for fieldid in np.unique(tbl['ALMAIMF_FIELDID']):\n",
    "        pfxs = prefixes[fieldid]\n",
    "        cube = SpectralCube.read(basepath + '/' + pfxs[f'finaliter_prefix_{band}']+\".image.tt0.fits\",\n",
    "                             format='fits', use_dask=False).minimal_subcube() # !filepath!\n",
    "        alma_rms = cube.mad_std()\n",
    "\n",
    "        ww = cube.wcs.celestial\n",
    "        ww._naxis = cube.shape[1:]\n",
    "\n",
    "        match = tbl['ALMAIMF_FIELDID'] == fieldid\n",
    "\n",
    "        crds = SkyCoord(tbl['ra'], tbl['dec'])[match]\n",
    "        sky_apertures = photutils.aperture.SkyCircularAperture(crds, aperture_radius)\n",
    "        apertures = sky_apertures.to_pixel(ww)\n",
    "\n",
    "        sky_annulus_aperture = photutils.aperture.SkyCircularAnnulus(crds, r_in=annulus_inner, r_out=annulus_outer)\n",
    "        annulus_apertures = sky_annulus_aperture.to_pixel(ww)\n",
    "\n",
    "        annulus_masks = annulus_apertures.to_mask(method='center')\n",
    "        data = cube[0]\n",
    "\n",
    "        bkg_median = []\n",
    "        for mask in annulus_masks:\n",
    "            annulus_data = mask.multiply(data)\n",
    "            if annulus_data is None:\n",
    "                bkg_median.append(np.nan * data.unit)\n",
    "                continue\n",
    "            annulus_data_1d = annulus_data[mask.data != 0]\n",
    "            _, median_sigclip, _ = sigma_clipped_stats(annulus_data_1d)\n",
    "            bkg_median.append(median_sigclip)\n",
    "        bkg_median = u.Quantity(bkg_median)\n",
    "        phot = photutils.aperture_photometry(data, apertures)\n",
    "        phot['annulus_median'] = bkg_median\n",
    "        phot['aper_bkg'] = bkg_median * apertures.area\n",
    "        phot['aper_sum_bkgsub'] = phot['aperture_sum'] - phot['aper_bkg']\n",
    "        phot['flux'] = phot['aper_sum_bkgsub'] / cube.pixels_per_beam * u.beam\n",
    "        phot['significant'] = phot['flux'] > 3 * alma_rms*u.beam\n",
    "\n",
    "        tbl[f'ALMA-IMF_{wlname}_flux'][match] = np.where(phot['significant'], phot['flux'], np.nan)\n",
    "        tbl[f'ALMA-IMF_{wlname}_eflux'][match] = np.where(np.isfinite(phot['flux']), alma_rms, np.nan)\n",
    "\n",
    "    return tbl\n",
    "\n",
    "# ----------------\n",
    "# MIPS\n",
    "# ----------------\n",
    "\n",
    "def add_MIPS_matches(tbl):\n",
    "    MIPS_IDs = tbl['MIPS']\n",
    "    row_limit = len(tbl)\n",
    "    MIPS_IDs_mask = np.array(['MG' in mid for mid in MIPS_IDs])\n",
    "    if any(MIPS_IDs_mask):\n",
    "        mips_match = Vizier(row_limit=row_limit,\n",
    "                            columns=[\"MIPSGAL\", \"S24\", \"e_S24\"]\n",
    "                           ).query_constraints(MIPSGAL=\"=,\"+\",\".join(map(str,\n",
    "                                                                         MIPS_IDs[MIPS_IDs_mask])),\n",
    "                                               catalog='J/AJ/149/64/catalog')[0]\n",
    "        mips_match.rename_column('MIPSGAL','MIPS')\n",
    "        tbl = table.join(tbl, mips_match, join_type='left')\n",
    "    else:\n",
    "        tbl['MIPS'] = ''\n",
    "        tbl['S24'] = np.nan\n",
    "        tbl['e_S24'] = np.nan\n",
    "    return tbl\n",
    "\n",
    "def add_mips_limits(tbl, coords, mipspath='/orange/adamginsburg/spitzer/mips/'):\n",
    "    # !filepath!\n",
    "    footprints = {fn: wcs.WCS(fits.getheader(fn)) for fn in glob.glob(f\"{mipspath}/MG[0-9][0-9][0-9][0-9][pn][0-9][0-9][0-9]_024.fits\")}\n",
    "\n",
    "    debug_counter = 0\n",
    "\n",
    "    rows = []\n",
    "    for crd in tqdm(coords.galactic):\n",
    "        match = False\n",
    "        for fn, ww in footprints.items():\n",
    "            if ww.footprint_contains(crd):\n",
    "                flx = get_flx(crd, fits.getdata(fn), ww)\n",
    "                rows.append(flx)\n",
    "                match = True\n",
    "                break\n",
    "        if not match:\n",
    "            rows.append(np.nan)\n",
    "\n",
    "    # use the last successful one\n",
    "    units = fits.getheader(fn)['BUNIT']\n",
    "\n",
    "    tbl.add_column(table.Column(name='M24_flux_uplim', data=rows, unit=units))\n",
    "\n",
    "    return tbl\n",
    "\n",
    "# ----------------\n",
    "# VVV\n",
    "# ----------------\n",
    "\n",
    "def add_VVV_matches(tbl):\n",
    "    virac_numbers = tbl['VIRAC']\n",
    "    row_limit = len(tbl)\n",
    "    # VIRAC uses numbers, not IDs, so we can just do comma-separated\n",
    "    virac_match = Vizier(row_limit=row_limit).query_constraints(srcid=\",\".join(map(str, virac_numbers[~virac_numbers.mask])),\n",
    "                                                           catalog='II/364/virac')[0]\n",
    "    virac_match.rename_column('srcid','VIRAC')\n",
    "\n",
    "    mskvirac = tbl['VIRAC'].mask.flatten().tolist()\n",
    "    tbl['VIRAC'].mask = False\n",
    "    tbl['VIRAC'][mskvirac] = -99999\n",
    "    rslt = table.join(tbl, virac_match, join_type='left', keys='VIRAC')\n",
    "    rslt.sort('SPICY')\n",
    "    rslt['VIRAC'].mask = mskvirac\n",
    "    \n",
    "    return rslt\n",
    "\n",
    "def add_VVV_limits(tbl, limits={\"Y\": 17,\n",
    "                  \"Z\": 17.5,\n",
    "                  \"J\": 16.5,\n",
    "                  \"H\": 16,\n",
    "                  \"Ks\": 15.5,}):\n",
    "\n",
    "    for key in limits.keys():\n",
    "        if f'{key}mag' and f'{key}ell' in tbl.keys():\n",
    "            tbl[f'{key}ell'].fill_value = limits[key]\n",
    "            tbl[f'{key}ell'][tbl['NIR data'] == \"VIRAC\"] = tbl[f'{key}ell'][tbl['NIR data'] == \"VIRAC\"].filled()\n",
    "        else: print(f'{key} band not found.')\n",
    "        \n",
    "    return tbl\n",
    "\n",
    "# ----------------\n",
    "# UKIDSS\n",
    "# ----------------\n",
    "\n",
    "def add_UKIDSS_matches(tbl):\n",
    "    \n",
    "    mskukidss = tbl['NIR data'] == \"UKIDSS\"\n",
    "    row_limit = len(tbl)\n",
    "    \n",
    "    ukidss_match = Vizier(row_limit=row_limit).query_constraints(UGPS=list(tbl['UKIDSS'][~mskukidss]),catalog='II/316/gps6')[0]\n",
    "    print(len(ukidss_match))\n",
    "    \n",
    "    ukidss_match.rename_column('UGPS','UKIDSS')\n",
    "    tbl['UKIDSS'][mskukidss] = -99999\n",
    "    \n",
    "    rslt = table.join(tbl, ukidss_match, join_type='left', keys='UKIDSS')\n",
    "    mskukidss = rslt['UKIDSS'] == '-99999'\n",
    "    \n",
    "    rslt['UKIDSS'][mskukidss] = np.ma.masked\n",
    "    rslt['UKIDSS'][mskukidss].mask = [mskukidss]\n",
    "    \n",
    "    rslt.sort('SPICY')\n",
    "    \n",
    "    return rslt\n",
    "\n",
    "def add_UKIDSS_limits(tbl, limits={\"J\": 19.9,\n",
    "                  \"H\": 19.0,\n",
    "                  \"K\": 18.8,}):\n",
    "\n",
    "    for key in limits.keys():\n",
    "        if f'{key}mag' and f'{key}ell' in tbl.keys():\n",
    "            tbl[f'{key}ell'].fill_value = limits[key]\n",
    "            tbl[f'{key}ell'][tbl['NIR data'] == \"UKIDSS\"] = tbl[f'{key}ell'][tbl['NIR data'] == \"UKIDSS\"].filled()\n",
    "        else: print(f'{key} band not found.')\n",
    "        \n",
    "    return tbl\n",
    "\n",
    "# ----------------\n",
    "# Herschel\n",
    "# ----------------\n",
    "\n",
    "def add_herschel_limits(tbl, coords, wls=[70,160,250,350,500], higalpath='/orange/adamginsburg/higal/'):\n",
    "    # !filepath!\n",
    "    rows = []\n",
    "    for crd in tqdm(coords.galactic):\n",
    "        galrnd = int(crd.galactic.l.deg)\n",
    "        flx = {wl: np.nan for wl in wls}\n",
    "        # search +/- 2 deg:\n",
    "        for gal in np.array([0,-1,1,-2,2]) + int(galrnd):\n",
    "            files = glob.glob(f'{higalpath}/Field{gal}_*.fits*') + glob.glob(f\"{higalpath}/l{gal}_*.fits*\")\n",
    "            if any(files):\n",
    "                fh = fits.open(files[0])[1]\n",
    "                ww = wcs.WCS(fh.header)\n",
    "                if ww.footprint_contains(crd):\n",
    "                    flx_ = {int(fn.split(\"Parallel\")[1].split(\"_\")[1]):\n",
    "                           get_flx(crd, fits.getdata(fn, ext=1), wcs.WCS(fits.getheader(fn, ext=1)))\n",
    "                           for fn in files\n",
    "                           if wcs.WCS(fits.getheader(fn, ext=1)).footprint_contains(crd)\n",
    "                          }\n",
    "                    if flx_[70] != 0:\n",
    "                        flx[70] = flx_[70]\n",
    "                        flx[160] = flx_[160]\n",
    "                    if 250 in flx_ and not np.isnan(flx_[250]):\n",
    "                        flx[250] = flx_[250]\n",
    "                        flx[350] = flx_[350]\n",
    "                        flx[500] = flx_[500]\n",
    "                    if flx[70] == 0 or np.isnan(flx[70]) or np.isnan(flx[250]):\n",
    "                        # wrong field?\n",
    "                        # print(f\"Failed match between {crd} and {files[0]}\")\n",
    "                        continue\n",
    "                    else:\n",
    "                        break\n",
    "        rows.append(flx)\n",
    "\n",
    "    # use the last successful one\n",
    "    units = {int(fn.split(\"Parallel\")[1].split(\"_\")[1]): fits.getheader(fn,\n",
    "                                                                        ext=1)['BUNIT']\n",
    "             for fn in files if wcs.WCS(fits.getheader(fn,\n",
    "                                                       ext=1)).footprint_contains(crd)\n",
    "            }\n",
    "\n",
    "    columns = {wl: [row[wl] for row in rows] for wl in wls}\n",
    "    for name, data in columns.items():\n",
    "        tbl.add_column(table.Column(name=name, data=data, unit=units[name]))\n",
    "    return tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb1db81-f7ee-46ee-b7c0-6f6c56dab67f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SED table prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09249af-f724-47c2-929b-86b5e7587126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch SPICY catalogue\n",
    "tbl, coords = get_spicy_tbl()\n",
    "print(len(tbl))\n",
    "\n",
    "# find which SPICY sources are in each ALMA FOV\n",
    "tbl = find_ALMAIMF_matches(tbl, coords)\n",
    "\n",
    "# reduce table to only the shared sources\n",
    "tblmsk = tbl['in_ALMAIMF']\n",
    "tbl, coords = tbl[tblmsk], coords[tblmsk]\n",
    "print(len(tbl))\n",
    "\n",
    "# mark rows by what NIR data is available\n",
    "has_ukidss = [row['UKIDSS'] != '                   ' for row in tbl]\n",
    "has_virac = [row['VIRAC'] is not np.ma.masked for row in tbl]\n",
    "tbl.add_column(\"      \",name='NIR data')\n",
    "tbl['NIR data'][has_ukidss] = \"UKIDSS\"\n",
    "tbl['NIR data'][has_virac] = \"VIRAC\"\n",
    "\n",
    "# append SPICY upper limits\n",
    "print(\"Adding SPICY upper limits\")\n",
    "tbl = add_spicylimits(tbl)\n",
    "\n",
    "# append ALMA-IMF photometry\n",
    "print(\"Adding ALMA-IMF photometry\")\n",
    "tbl = add_alma_photometry(tbl, band='b3', wlname='3mm')\n",
    "tbl = add_alma_photometry(tbl, band='b6', wlname='1mm')\n",
    "\n",
    "# convert ALMA-IMF fluxes to mJy/beam\n",
    "print(\"Converting ALMA fluxes to mJy/beam\")\n",
    "for colname in ['ALMA-IMF_3mm_flux', 'ALMA-IMF_3mm_eflux', 'ALMA-IMF_1mm_flux', 'ALMA-IMF_1mm_eflux']:\n",
    "    tbl[colname] = tbl[colname] * u.Jy / u.beam\n",
    "    tbl[colname] = tbl[colname].to(u.mJy / u.beam)\n",
    "\n",
    "# add MIPS data points and upper limits\n",
    "print(\"Adding MIPS match data\")\n",
    "tbl = add_MIPS_matches(tbl)\n",
    "print(\"Adding MIPS limit data\")\n",
    "tbl = add_mips_limits(tbl, coords)\n",
    "tbl.sort('SPICY') # previous function messes row order\n",
    "\n",
    "# populate MIPS error column with upper limits, rename MIPS columns\n",
    "tbl['e_S24'][tbl['e_S24'].mask] = tbl['M24_flux_uplim'][tbl['e_S24'].mask]\n",
    "tbl.rename_column('S24', 'Spitzer/MIPS.24mu_flux')\n",
    "tbl.rename_column('e_S24', 'Spitzer/MIPS.24mu_eflux')\n",
    "\n",
    "# add VVV data points, populate errors with upper limits\n",
    "print(\"Adding VVV data\")\n",
    "tbl = add_VVV_matches(tbl)\n",
    "tbl.rename_column('KsEll', 'Ksell') # so that add_VVV_limits works right\n",
    "print(\"Adding VVV upper limits\")\n",
    "tbl = add_VVV_limits(tbl)\n",
    "\n",
    "# append UKIDSS data points for matches\n",
    "print(\"Adding UKIDSS data\")\n",
    "tbl = add_UKIDSS_matches(tbl)\n",
    "\n",
    "# table column housekeeping\n",
    "tbl['Jmag_1'][tbl['NIR data'] == \"UKIDSS\"] = tbl['Jmag_2'][tbl['NIR data'] == \"UKIDSS\"] # move J data\n",
    "tbl.rename_column('Jmag_1', 'Jmag')\n",
    "tbl['Jell'][tbl['NIR data'] == \"UKIDSS\"] = tbl['e_Jmag'][tbl['NIR data'] == \"UKIDSS\"]\n",
    "\n",
    "tbl['Hmag_1'][tbl['NIR data'] == \"UKIDSS\"] = tbl['Hmag_2'][tbl['NIR data'] == \"UKIDSS\"] # move H data\n",
    "tbl.rename_column('Hmag_1', 'Hmag')\n",
    "tbl['Hell'][tbl['NIR data'] == \"UKIDSS\"] = tbl['e_Hmag'][tbl['NIR data'] == \"UKIDSS\"]\n",
    "\n",
    "tbl.rename_column('Kmag1', 'Kmag') # tweak K column\n",
    "tbl.rename_column('e_Kmag1', 'Kell')\n",
    "\n",
    "# populate UKIDSS errors with upper limits\n",
    "print(\"Adding UKIDSS upper limits\")\n",
    "tbl = add_UKIDSS_limits(tbl)\n",
    "\n",
    "# append Herschel data points\n",
    "print(\"Adding Herschel limits\")\n",
    "tbl = add_herschel_limits(tbl, coords)\n",
    "\n",
    "# define Herschel beams\n",
    "Herschel_Beams = {'70': np.pi*9.7*10.7*u.arcsec**2 / (8*np.log(2)),\n",
    "                  '160': np.pi*13.2*13.9*u.arcsec**2 / (8*np.log(2)),\n",
    "                  '250': np.pi*22.8*23.9*u.arcsec**2 / (8*np.log(2)),\n",
    "                  '350': np.pi*29.3*31.3*u.arcsec**2 / (8*np.log(2)),\n",
    "                  '500': np.pi*41.1*43.8*u.arcsec**2 / (8*np.log(2)),\n",
    "                 }\n",
    "\n",
    "# all Herschel values will be treated as upper limits\n",
    "print(\"Converting Herschel fluxes to upper limits\")\n",
    "tbl[\"Herschel/Pacs.blue_eflux\"] = (tbl['70' ].quantity * u.pixel).to(u.mJy)\n",
    "tbl[\"Herschel/Pacs.red_eflux\"]  = (tbl['160'].quantity * u.pixel).to(u.mJy)\n",
    "tbl[\"Herschel/SPIRE.PSW_eflux\"] = (tbl['250'].quantity * Herschel_Beams['250']).to(u.mJy)\n",
    "tbl[\"Herschel/SPIRE.PMW_eflux\"] = (tbl['350'].quantity * Herschel_Beams['350']).to(u.mJy)\n",
    "tbl[\"Herschel/SPIRE.PLW_eflux\"] = (tbl['500'].quantity * Herschel_Beams['500']).to(u.mJy)\n",
    "for x in ['Pacs.blue','Pacs.red','SPIRE.PSW','SPIRE.PMW','SPIRE.PLW']:\n",
    "    tbl[f\"Herschel/{x}_flux\"] = np.nan \n",
    "    \n",
    "# housekeeping\n",
    "for errcolname in ['Zell','Yell','Jell','Hell','Kell','Ksell']:\n",
    "    tbl[errcolname].unit = 'mag'\n",
    "\n",
    "# UKIDSS mag-to-flux conversion\n",
    "# acquire filternames and zero points\n",
    "sed_filters, wavelength_dict, filternames, zpts = get_filters(\"north\")\n",
    "# define magcols and emagcols, for UKIDSS fields\n",
    "magcols = ['Jmag', 'Hmag', 'Kmag','mag3_6', 'mag4_5', 'mag5_8', 'mag8_0']\n",
    "emagcols = ['Jell', 'Hell', 'Kell','e_mag3_6', 'e_mag4_5', 'e_mag5_8', 'e_mag8_0']\n",
    "# convert magnitudes to fluxes\n",
    "print(\"Converting magnitudes to fluxes\")\n",
    "tbl_ukidss = tbl[[n in ukidss_fields for n in tbl['ALMAIMF_FIELDID']]]\n",
    "tbl_ukidss = mag_to_flux(tbl_ukidss, magcols, emagcols, zpts, filternames)\n",
    "\n",
    "# VIRAC mag-to-flux conversion\n",
    "# acquire filternames and zero points\n",
    "sed_filters, wavelength_dict, filternames, zpts = get_filters(\"south\")\n",
    "# define magcols and emagcols, for VIRAC fields\n",
    "magcols = ['Ymag', 'Zmag', 'Jmag', 'Hmag', 'Ksmag','mag3_6', 'mag4_5', 'mag5_8', 'mag8_0']\n",
    "emagcols = ['Yell', 'Zell', 'Jell', 'Hell', 'Ksell','e_mag3_6', 'e_mag4_5', 'e_mag5_8', 'e_mag8_0']\n",
    "# convert magnitudes to fluxes\n",
    "print(\"Converting magnitudes to fluxes\")\n",
    "tbl_virac = tbl[[n in virac_fields for n in tbl['ALMAIMF_FIELDID']]]\n",
    "tbl_virac = mag_to_flux(tbl_virac, magcols, emagcols, zpts, filternames)\n",
    "\n",
    "tbl = vstack([tbl_ukidss, tbl_virac])\n",
    "tbl.sort('SPICY')\n",
    "\n",
    "# add distances to each field, based on values in the ALMA-IMF paper\n",
    "print(\"Adding distances\")\n",
    "distances = {\"G10\": 4.95,\"G12\": 2.4,\"W43MM1\": 5.5,\"W43MM2\": 5.5,\"W43MM3\": 5.5,\"W51-E\": 5.4,\"W51IRS2\": 5.4,\"G338\": 3.9,\n",
    "             \"G008\": 3.4,\"G327\": 2.5,\"G328\": 2.5,\"G333\": 4.2,\"G337\": 2.7,\"G351\": 2.0,\"G353\": 2.0,}\n",
    "tbl.add_column(0.00*u.kpc,name='Distance')\n",
    "for key in distances:\n",
    "    tbl['Distance'][tbl['ALMAIMF_FIELDID'] == key] = distances[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc97ac7-c836-42fb-ada0-a8137958fbfa",
   "metadata": {},
   "source": [
    "Saving data to files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff901761-e9ba-4f9b-b727-70dbc76dbee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut table down to only necessary information\n",
    "tbl = tbl['SPICY','ra','dec','l','b','ALMAIMF_FIELDID','Distance','NIR data',\n",
    "          'Spitzer/IRAC.I1_flux','Spitzer/IRAC.I1_eflux','Spitzer/IRAC.I2_flux','Spitzer/IRAC.I2_eflux','Spitzer/IRAC.I3_flux','Spitzer/IRAC.I3_eflux','Spitzer/IRAC.I4_flux','Spitzer/IRAC.I4_eflux',\n",
    "          'ALMA-IMF_3mm_flux','ALMA-IMF_3mm_eflux','ALMA-IMF_1mm_flux','ALMA-IMF_1mm_eflux',\n",
    "          'Spitzer/MIPS.24mu_flux','Spitzer/MIPS.24mu_eflux',\n",
    "          'UKIRT/UKIDSS.J_flux','UKIRT/UKIDSS.J_eflux','UKIRT/UKIDSS.H_flux','UKIRT/UKIDSS.H_eflux','UKIRT/UKIDSS.K_flux','UKIRT/UKIDSS.K_eflux',\n",
    "          'Paranal/VISTA.Ks_flux','Paranal/VISTA.Ks_eflux','Paranal/VISTA.Z_flux','Paranal/VISTA.Z_eflux','Paranal/VISTA.Y_flux','Paranal/VISTA.Y_eflux','Paranal/VISTA.J_flux','Paranal/VISTA.J_eflux','Paranal/VISTA.H_flux','Paranal/VISTA.H_eflux',\n",
    "          'Herschel/Pacs.blue_flux','Herschel/Pacs.blue_eflux','Herschel/Pacs.red_flux','Herschel/Pacs.red_eflux','Herschel/SPIRE.PMW_flux','Herschel/SPIRE.PMW_eflux','Herschel/SPIRE.PSW_flux','Herschel/SPIRE.PSW_eflux','Herschel/SPIRE.PLW_flux','Herschel/SPIRE.PLW_eflux']\n",
    "\n",
    "tbl.meta['description'] = None\n",
    "\n",
    "# save table as individual fits files per field\n",
    "for fieldid in np.unique(tbl['ALMAIMF_FIELDID']):\n",
    "    tbl[tbl['ALMAIMF_FIELDID'] == fieldid].write(f'/blue/adamginsburg/adamginsburg/SPICY_ALMAIMF/BriceTingle/Region_tables/Unfitted/{fieldid}', format='fits', overwrite=True) # !filepath!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
